---
title: "Data quality filters, and subsetting the data for manageability"
authors: Genoveva Gonzalez Mirelis and Rebecca Ross
date: "Last Rendered on `r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_notebook: 
    toc: yes
    toc_depth: 2
    toc_float: yes
    fig_width: 7
    fig_height: 7
always_allow_html: true 
---

# Introduction

In this notebook we filter out stations and/or samples that fail various data quality filters. We also subset the data to make it more or less one third of the total.

Requirements: sppdens, sample_info, refer

Outputs: sppdens_qc

# Libraries

```{r}
library(tidyverse)
```

# Station-level quality assessment

## Assess data completeness
We should use only video lines where data is complete. We determine that by looking at the total number of biological annotations relative to the towed distance. Note that total number of biological annotations depends on species richness, so expect large variation 
```{r}
hist(refer$total_bio/refer$towed_distance, main = "Distribution of records:distance ratio",
     xlab = "total records : towed distance")
```

## Make a list of "good" stations
Check how much data we would be using/discarding for each threshold
```{r}
thres <- 5
good <- refer$nSampleNumber[which(refer$total_bio/refer$towed_distance<thres)]
refer %>% filter(nSampleNumber%in%unique(sample_info$VL)) %>%
  filter(!(nSampleNumber%in%good)) #%>%
  print(n=1000)
  View
```
